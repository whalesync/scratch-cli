import { createFileId, DataFolderId, FileId, FolderId, UNPUBLISHED_PREFIX, WorkbookId } from '@spinner/shared-types';
import matter from 'gray-matter';
import { Knex } from 'knex';
import _ from 'lodash';
import { WSLogger } from 'src/logger';
import {
  BaseColumnSpec,
  BaseJsonTableSpec,
  BaseTableSpec,
  ConnectorFile,
  ConnectorRecord,
} from '../remote-service/connectors/types';
import { assertFolderPathIsValid, deduplicateFileName, normalizeFileName, resolveBaseFileName } from './util';

// Table name constant
export const FILES_TABLE = 'files';

// Column name constants for the files table

// The internal unique identifier for the file
export const FILE_ID_COLUMN = 'id';

// The remote identifier for the file if linked to a remote source
export const REMOTE_ID_COLUMN = 'remote_id';

// The folder the file belongs to, used to perform folder-scoped operations on files without needind to string-match the path
export const FOLDER_ID_COLUMN = 'folder_id';

// The full path of the file in the folder hierarchy including all of the folders and ending with the file name
export const PATH_COLUMN = 'path';

// A generated value based on the path, providing the name of the file
// File name is managed by scratch though the initial value may be sourced from a title or name field in the connector record
export const FILE_NAME_COLUMN = 'name';

// The active content of the file, as it appears in the UI
export const CONTENT_COLUMN = 'content';

// The original content of the file, as it was when it was first created or pulled from the remote source.
export const ORIGINAL_COLUMN = 'original';

// The suggested content of the file, as generated by the agent
export const SUGGESTED_COLUMN = 'suggested';

// The flag indicating that the file was deleted by the agent and is pending acceptance by the user
export const SUGGESTED_DELETE_COLUMN = 'suggested_delete';

// Index of non-body Front Matter properties stored as key-value pairs. We can use JSON queries to create filters and sort
export const METADATA_COLUMN = 'metadata';

// The timestamp when the file was created
export const CREATED_AT_COLUMN = 'created_at';

// The timestamp when the file was last updated
export const UPDATED_AT_COLUMN = 'updated_at';

// The flag indicating that the file was deleted by the user and should get deleted from the remote source
export const DELETED_COLUMN = 'deleted';

// The flag indicating that the file has been modified since the original content was set
export const DIRTY_COLUMN = 'dirty';

// A JSON object containing connector-specific errors for the file
export const ERRORS_COLUMN = 'errors';

// tracks seen state for the file during sync operations
export const SEEN_COLUMN = 'seen';

export const FILE_PATH_PREFIX = '/';

/**
 * Different states of a file record
 * - new file (suggestion): suggested <> null, original === null
 * - new file (accepted): content <> null, original === null
 * - deleted: deleted === true
 * - deleted (suggested): suggested_delete === true, suggested  === ''
 * - modified: content <> original
 * - pending change: suggested <> null && suggested <> content
 * - dirty: the file record has changed since the original content was set. Just a quick filter flag
 */

/**
 * Represents a single file record from the files table
 */
export type FileDbRecord = {
  [FILE_ID_COLUMN]: string;
  [REMOTE_ID_COLUMN]: string | null;
  [FOLDER_ID_COLUMN]: string;
  [PATH_COLUMN]: string; // Cached full path
  [FILE_NAME_COLUMN]: string;
  [CONTENT_COLUMN]: string | null;
  [ORIGINAL_COLUMN]: string | null;
  [SUGGESTED_COLUMN]: string | null;
  [METADATA_COLUMN]: Record<string, unknown>;
  [CREATED_AT_COLUMN]: Date;
  [UPDATED_AT_COLUMN]: Date;
  [DELETED_COLUMN]: boolean;
  [SUGGESTED_DELETE_COLUMN]: boolean;
  [DIRTY_COLUMN]: boolean;
  [ERRORS_COLUMN]: Record<string, unknown>;
  [SEEN_COLUMN]: boolean;
};

const MAX_UNIQUE_FILE_NAME_ATTEMPTS = 20;

export class WorkbookDb {
  public knex!: Knex;

  init(knex: Knex) {
    this.knex = knex;
  }

  /**
   * Updates the paths of all files in a folder to match the new folder path.
   */
  async updateFilePathsInFolder(workbookId: WorkbookId, folderId: string, folderPath: string): Promise<void> {
    const prefix = folderPath === '/' ? '' : folderPath;
    await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(FOLDER_ID_COLUMN, folderId)
      .update({
        [PATH_COLUMN]: this.getKnex().raw("? || '/' || ??", [prefix, FILE_NAME_COLUMN]),
      });
  }

  /**
   * Creates a new schema for a workbook and creates the files table within it
   */
  async createForWorkbook(workbookId: WorkbookId) {
    // Create the schema if it doesn't exist
    await this.getKnex().raw(`CREATE SCHEMA IF NOT EXISTS "${workbookId}"`);

    // Check if the files table already exists
    const tableExists = await this.getKnex().schema.withSchema(workbookId).hasTable(FILES_TABLE);

    if (!tableExists) {
      // Create the central files table
      await this.getKnex()
        .schema.withSchema(workbookId)
        .createTable(FILES_TABLE, (t) => {
          t.text(FILE_ID_COLUMN).primary();
          t.text(REMOTE_ID_COLUMN).nullable().index();
          t.text(FOLDER_ID_COLUMN).index();
          t.text(PATH_COLUMN).unique(); // Cached path
          t.text(FILE_NAME_COLUMN);
          t.text(CONTENT_COLUMN).nullable();
          t.text(ORIGINAL_COLUMN).nullable();
          t.text(SUGGESTED_COLUMN).nullable();
          t.jsonb(METADATA_COLUMN).defaultTo('{}');
          t.timestamp(CREATED_AT_COLUMN, { useTz: false }).defaultTo(this.getKnex().fn.now());
          t.timestamp(UPDATED_AT_COLUMN, { useTz: false }).defaultTo(this.getKnex().fn.now());
          t.boolean(DELETED_COLUMN).defaultTo(false);
          t.boolean(SUGGESTED_DELETE_COLUMN).defaultTo(false);
          t.boolean(DIRTY_COLUMN).defaultTo(false);
          t.jsonb(ERRORS_COLUMN).defaultTo('{}');
          t.boolean(SEEN_COLUMN).defaultTo(false);
        });
    }
  }

  async listFilesAndFolders(workbookId: WorkbookId, parentFolderPath: string): Promise<FileDbRecord[]> {
    assertFolderPathIsValid(parentFolderPath);
    // Ensure the schema and files table exist (handles workbooks created before files feature)
    await this.createForWorkbook(workbookId);

    const result = await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(PATH_COLUMN, 'like', `${parentFolderPath}%`)
      .orderBy(PATH_COLUMN, 'asc')
      .select('*');

    return result;
  }

  async cleanupSchema(workbookId: WorkbookId) {
    await this.getKnex().raw(`DROP SCHEMA IF EXISTS "${workbookId}" CASCADE`);
  }

  /**
   * Lists all files in a workbook (not filtered by path)
   */
  async listAllFiles(workbookId: WorkbookId): Promise<FileDbRecord[]> {
    // Ensure the schema and files table exist (handles workbooks created before files feature)
    await this.createForWorkbook(workbookId);

    const result = await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(DELETED_COLUMN, false)
      .orderBy(FILE_NAME_COLUMN, 'asc')
      .select(
        FILE_ID_COLUMN,
        REMOTE_ID_COLUMN,
        FOLDER_ID_COLUMN,
        PATH_COLUMN,
        FILE_NAME_COLUMN,
        CONTENT_COLUMN,
        ORIGINAL_COLUMN,
        SUGGESTED_COLUMN,
        METADATA_COLUMN,
        CREATED_AT_COLUMN,
        UPDATED_AT_COLUMN,
        DELETED_COLUMN,
        SUGGESTED_DELETE_COLUMN,
        DIRTY_COLUMN,
        ERRORS_COLUMN,
        SEEN_COLUMN,
      );

    return result;
  }

  /**
   * Returns a single FileDbRecord for a unique ID
   */
  async getFileById(workbookId: WorkbookId, fileId: FileId): Promise<FileDbRecord | null> {
    const result = await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(FILE_ID_COLUMN, fileId)
      .select('*')
      .first();

    return result ?? null;
  }

  /**
   * Finds a file using its full path
   * @param workbookId - The workbook ID
   * @param fullPath - The full path of the file
   * @returns The FileDbRecord if found, otherwise null
   */
  async getFileByPath(workbookId: WorkbookId, fullPath: string): Promise<FileDbRecord | null> {
    const result = await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(PATH_COLUMN, fullPath)
      .select('*')
      .first();

    return result ?? null;
  }

  async getFilesByFolderId(
    workbookId: WorkbookId,
    folderId: string,
    options?: { limit?: number; offset?: number },
  ): Promise<FileDbRecord[]> {
    let query = this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(FOLDER_ID_COLUMN, folderId)
      .orderBy(FILE_NAME_COLUMN, 'asc');

    if (options?.limit !== undefined) {
      query = query.limit(options.limit);
    }

    if (options?.offset !== undefined) {
      query = query.offset(options.offset);
    }

    const results = await query.select('*');

    return results;
  }

  async countFilesByFolderId(workbookId: WorkbookId, folderId: string): Promise<number> {
    const result = await this.getKnex()(FILES_TABLE)
      .withSchema(workbookId)
      .where(FOLDER_ID_COLUMN, folderId)
      .count('* as count')
      .first<{ count: string }>();

    return parseInt(result?.count ?? '0', 10);
  }

  /**
   * Returns FileDbRecords for a list of file IDs
   */
  async getFilesByIds(workbookId: WorkbookId, fileIds: FileId[]): Promise<FileDbRecord[]> {
    if (fileIds.length === 0) {
      return [];
    }

    const results = await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .whereIn(FILE_ID_COLUMN, fileIds)
      .select('*');

    return results;
  }

  /**
   * Finds files matching a name pattern within an optional path prefix.
   * Supports glob-like patterns: * matches any characters, ? matches single character.
   * @param workbookId - The workbook ID
   * @param namePattern - Glob pattern for file name (e.g., "*.md", "test*", "file?.txt")
   * @param pathPrefix - Optional path prefix to search within (e.g., "/emails")
   * @returns Matching FileDbRecords
   */
  async findFilesByPattern(
    workbookId: WorkbookId,
    namePattern: string,
    pathPrefix?: string,
    recursive: boolean = true,
  ): Promise<FileDbRecord[]> {
    // Convert glob pattern to SQL LIKE pattern
    // * -> % (match any characters)
    // ? -> _ (match single character)
    // Escape existing % and _ characters
    const sqlPattern = namePattern.replace(/%/g, '\\%').replace(/_/g, '\\_').replace(/\*/g, '%').replace(/\?/g, '_');

    let query = this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(DELETED_COLUMN, false)
      .where(FILE_NAME_COLUMN, 'like', sqlPattern);

    // If path prefix is specified, filter by path
    if (pathPrefix) {
      const normalizedPrefix = pathPrefix.endsWith('/') ? pathPrefix : `${pathPrefix}/`;

      if (recursive) {
        // Recursive: match any path starting with the prefix
        query = query.where(PATH_COLUMN, 'like', `${normalizedPrefix}%`);
      } else {
        // Non-recursive: match direct children only
        // We use a regex to ensure there are no more slashes after the prefix+filename
        // escaped regex for postgres: ^/prefix/[^/]+$
        // Note: PATH_COLUMN includes the filename.
        // So we want paths that start with prefix, and have NO additional slashes after the prefix.

        // Example: prefix = '/F4/'
        // Match: '/F4/file.txt'
        // No match: '/F4/sub/file.txt'

        // Postgres regex: ^/prefix/[^/]+$
        const regex = `^${normalizedPrefix}[^/]+$`;
        query = query.where(PATH_COLUMN, '~', regex);
      }
    } else if (!recursive) {
      // Non-recursive search at root (/)
      // Match paths that have NO slashes (except leading slash if paths store it)
      // Our paths start with slash. So root files are /filename.
      // Regex: ^/[^/]+$
      query = query.where(PATH_COLUMN, '~', '^/[^/]+$');
    }

    const results = await query.orderBy(PATH_COLUMN, 'asc').select('*');

    return results;
  }

  /**
   * Searches file contents for a pattern (like grep).
   * Uses SQL ILIKE for case-insensitive search.
   * @param workbookId - The workbook ID
   * @param searchPattern - Text pattern to search for in file content
   * @param pathPrefix - Optional path prefix to search within
   * @returns Matching FileDbRecords
   */
  async grepFiles(workbookId: WorkbookId, searchPattern: string, pathPrefix?: string): Promise<FileDbRecord[]> {
    // Escape special SQL LIKE characters in the search pattern
    const escapedPattern = searchPattern.replace(/%/g, '\\%').replace(/_/g, '\\_');

    let query = this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(DELETED_COLUMN, false)
      .whereNotNull(CONTENT_COLUMN)
      .where(CONTENT_COLUMN, 'ilike', `%${escapedPattern}%`);

    // If path prefix is specified, filter by path
    if (pathPrefix) {
      const normalizedPrefix = pathPrefix.endsWith('/') ? pathPrefix : `${pathPrefix}/`;
      query = query.where(PATH_COLUMN, 'like', `${normalizedPrefix}%`);
    }

    const results = await query.orderBy(PATH_COLUMN, 'asc').select('*');

    return results;
  }

  /**
   * Accepts suggestions for a file by path
   * Copies the suggested column value to content, sets suggested to null, and updates the timestamp
   * Only updates files where suggested is not null
   */
  async acceptSuggestionOnFile(workbookId: WorkbookId, fileId: FileId): Promise<number> {
    const file = await this.getFileById(workbookId, fileId);

    if (!file) {
      throw new FileNotFoundError(fileId, workbookId);
    }

    if (file.suggested === null && file.suggested_delete === false) {
      return 0;
    }

    // check the suggested delete first
    if (file.suggested_delete === true) {
      // accept the suggestion and delete the file
      await this.deleteFileById(workbookId, file.id as FileId, false);
      return 1;
    }

    // this is an update operation, so we need to recalculate the metadata
    let metadata: Record<string, unknown> = {};

    if (file.suggested && file.suggested.length > 0) {
      try {
        const parsed = matter(file.suggested);
        metadata = parsed.data as Record<string, unknown>;
      } catch (error) {
        WSLogger.error({
          source: 'WorkbookDb',
          message: `Failed to parse suggested content as frontmatter`,
          stack: error instanceof Error ? error.stack : undefined,
        });
      }
    }

    const result = await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(FILE_ID_COLUMN, fileId)
      .update({
        [CONTENT_COLUMN]: this.getKnex().raw('??', [SUGGESTED_COLUMN]),
        [SUGGESTED_COLUMN]: null,
        [METADATA_COLUMN]: metadata,
        [UPDATED_AT_COLUMN]: this.getKnex().fn.now(),
        [DIRTY_COLUMN]: true,
      });

    return result ?? 0;
  }

  async rejectSuggestionOnFile(workbookId: WorkbookId, fileId: FileId): Promise<number> {
    const result = await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(FILE_ID_COLUMN, fileId)
      .whereNotNull(SUGGESTED_COLUMN)
      .update({
        [SUGGESTED_COLUMN]: null,
        [SUGGESTED_DELETE_COLUMN]: false,
      });

    return result;
  }

  async acceptSuggestionsForFolder(workbookId: WorkbookId, folderId: FolderId): Promise<number> {
    // TODO: this needs to to be rewriten to handle suggestions one at a time, inside of a transaction in order
    // to handle the deletes, updates and metadata recalculations properly

    const result = await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(FOLDER_ID_COLUMN, folderId)
      .whereNotNull(SUGGESTED_COLUMN)
      .update({
        [CONTENT_COLUMN]: this.getKnex().raw('??', [SUGGESTED_COLUMN]),
        [SUGGESTED_COLUMN]: null,
        [UPDATED_AT_COLUMN]: this.getKnex().fn.now(),
      });

    return result;
  }

  async rejectSuggestionsForFolder(workbookId: WorkbookId, folderId: FolderId): Promise<number> {
    const result = await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(FOLDER_ID_COLUMN, folderId)
      .whereNotNull(SUGGESTED_COLUMN)
      .update({
        [SUGGESTED_COLUMN]: null,
        [SUGGESTED_DELETE_COLUMN]: false,
      });

    return result;
  }

  /**
   * Creates a new file in the database using a folder ID instead of path
   * This is the new method that works with the folder entity
   */
  async createFileWithFolderId(
    workbookId: WorkbookId,
    fileName: string,
    folderId: string | null,
    path: string,
    content: string | null,
    isSuggestion: boolean = false,
  ): Promise<FileId> {
    const fileId = createFileId();
    const tempRemoteId = `${UNPUBLISHED_PREFIX}${fileId}`;

    let metadata: Record<string, unknown> = {};
    if (content && !isSuggestion) {
      try {
        const parsed = matter(content);
        metadata = parsed.data as Record<string, unknown>;
      } catch (error) {
        WSLogger.error({
          source: 'WorkbookDb',
          message: `Failed to parse content as frontmatter`,
          stack: error instanceof Error ? error.stack : undefined,
        });
      }
    }

    await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .insert({
        [FILE_ID_COLUMN]: fileId,
        [REMOTE_ID_COLUMN]: tempRemoteId,
        [FOLDER_ID_COLUMN]: folderId ?? '',
        [PATH_COLUMN]: path,
        [FILE_NAME_COLUMN]: fileName,
        [CONTENT_COLUMN]: isSuggestion ? null : content,
        [ORIGINAL_COLUMN]: null,
        [SUGGESTED_COLUMN]: isSuggestion ? content : null,
        [METADATA_COLUMN]: metadata,
        [UPDATED_AT_COLUMN]: this.getKnex().fn.now(),
        [CREATED_AT_COLUMN]: this.getKnex().fn.now(),
        [DIRTY_COLUMN]: !isSuggestion,
      });

    return fileId;
  }

  /**
   * Updates a file by ID with optional name, folder, and content changes
   */
  async updateFileById(
    workbookId: WorkbookId,
    fileId: FileId,
    updates: {
      name?: string;
      folderId?: string | null;
      content?: string | null;
      path?: string;
    },
  ): Promise<void> {
    const file = await this.getFileById(workbookId, fileId);
    if (!file) {
      throw new FileNotFoundError(fileId, workbookId);
    }

    const updateData: Partial<FileDbRecord> = {
      [UPDATED_AT_COLUMN]: this.getKnex().fn.now() as unknown as Date,
    };

    if (updates.name !== undefined) {
      updateData[FILE_NAME_COLUMN] = updates.name;
    }

    if (updates.folderId !== undefined) {
      updateData[FOLDER_ID_COLUMN] = updates.folderId ?? '';
    }

    if (updates.path !== undefined) {
      updateData[PATH_COLUMN] = updates.path;
    }

    if (updates.content !== undefined) {
      updateData[CONTENT_COLUMN] = updates.content;
      updateData[DIRTY_COLUMN] = true;

      // Parse metadata from content
      if (updates.content) {
        try {
          const parsed = matter(updates.content);
          updateData[METADATA_COLUMN] = parsed.data as Record<string, unknown>;
        } catch (error) {
          WSLogger.error({
            source: 'WorkbookDb',
            message: `Failed to parse content as frontmatter`,
            stack: error instanceof Error ? error.stack : undefined,
          });
        }
      }
    }

    await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(FILE_ID_COLUMN, fileId)
      .update(updateData);
  }

  /**
   * Deletes a file from the database
   * If the file is a suggestion, sets the suggested column to empty string and sets the suggested_delete flag
   * If the file is not a suggestion, checks if the record has original content, if so flags it for deletion, otherwise deletes from table
   */
  async deleteFileById(workbookId: WorkbookId, fileId: FileId, isSuggestion: boolean): Promise<void> {
    if (isSuggestion) {
      // Suggested delete: set suggested column to empty string and set suggested_delete flag
      await this.getKnex()<FileDbRecord>(FILES_TABLE)
        .withSchema(workbookId)
        .where(FILE_ID_COLUMN, fileId)
        .update({
          [SUGGESTED_COLUMN]: '',
          [SUGGESTED_DELETE_COLUMN]: true,
          [UPDATED_AT_COLUMN]: this.getKnex().fn.now(),
        });
    } else {
      const record = await this.getKnex()<FileDbRecord>(FILES_TABLE)
        .withSchema(workbookId)
        .where(FILE_ID_COLUMN, fileId)
        .first<{ [ORIGINAL_COLUMN]: string | null }>();

      if (record?.[ORIGINAL_COLUMN] !== null) {
        // Record has original content, flag it for deletion instead of hard deleting
        await this.getKnex()<FileDbRecord>(FILES_TABLE)
          .withSchema(workbookId)
          .where(FILE_ID_COLUMN, fileId)
          .update({
            [DELETED_COLUMN]: true,
            [DIRTY_COLUMN]: true,
            [UPDATED_AT_COLUMN]: this.getKnex().fn.now(),
          });
      } else {
        // No original content, harddelete from table
        await this.getKnex()<FileDbRecord>(FILES_TABLE).withSchema(workbookId).where(FILE_ID_COLUMN, fileId).delete();
      }
    }
  }

  /**
   * Clears the delete flag on a file
   */
  async undeleteFileById(workbookId: WorkbookId, fileId: FileId): Promise<void> {
    await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(FILE_ID_COLUMN, fileId)
      .update({
        [DELETED_COLUMN]: false,
      });
  }

  /**
   * Sets the dirty state of a file
   */
  async setFileDirtyState(workbookId: WorkbookId, fileId: FileId, dirty: boolean): Promise<void> {
    await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(FILE_ID_COLUMN, fileId)
      .update({
        [DIRTY_COLUMN]: dirty,
        [UPDATED_AT_COLUMN]: this.getKnex().fn.now(),
      });
  }

  /**
   * Updates the content of a file
   */
  async updateFile(
    workbookId: WorkbookId,
    fileId: FileId,
    content: string | null,
    isSuggestion: boolean,
  ): Promise<void> {
    if (isSuggestion) {
      await this.getKnex()<FileDbRecord>(FILES_TABLE)
        .withSchema(workbookId)
        .where(FILE_ID_COLUMN, fileId)
        .update({
          [SUGGESTED_COLUMN]: content,
          [UPDATED_AT_COLUMN]: this.getKnex().fn.now(),
        });
    } else {
      // Parse the content into a frontmatter object and extract the metadata to save to the database
      let metadata: Record<string, unknown> = {};

      if (content) {
        try {
          const parsed = matter(content);
          metadata = parsed.data as Record<string, unknown>;
        } catch (error) {
          WSLogger.error({
            source: 'WorkbookDb',
            message: `Failed to parse content as frontmatter`,
            stack: error instanceof Error ? error.stack : undefined,
          });

          // If parsing fails, just use empty metadata
          metadata = {};
        }
      }

      await this.getKnex()<FileDbRecord>(FILES_TABLE)
        .withSchema(workbookId)
        .where(FILE_ID_COLUMN, fileId)
        .update({
          [CONTENT_COLUMN]: content,
          [METADATA_COLUMN]: metadata,
          [UPDATED_AT_COLUMN]: this.getKnex().fn.now(),
          [DIRTY_COLUMN]: true,
        });
    }
  }

  /**
   * Deletes all of the files related to a specific folder
   * This only removes the files directly related to the folder, it does not remove the folder itself or files in child folders
   */
  async deleteFilesInFolder(workbookId: WorkbookId, folderId: FolderId | DataFolderId): Promise<void> {
    // NOTE: this should probably be done in batches with a progress callback
    await this.getKnex()<FileDbRecord>(FILES_TABLE).withSchema(workbookId).where(FOLDER_ID_COLUMN, folderId).delete();
  }

  /**
   * Upserts files from an array of ConnectorRecord objects.
   * Converts each ConnectorRecord to Front Matter markdown format.
   * The main content body is extracted from the field specified by mainContentColumnRemoteId in the TableSpec.
   * All other fields are stored as metadata in the YAML front matter.
   *
   * @param workbookId - The workbook ID
   * @param folderId - The folder ID where files will be stored
   * @param records - Array of ConnectorRecord objects to upsert
   * @param tableSpec - TableSpec containing column definitions and mainContentColumnRemoteId
   * @returns Promise that resolves when all files have been upserted
   */
  async upsertFilesFromConnectorRecords<T extends BaseColumnSpec>(
    workbookId: WorkbookId,
    folderId: string,
    parentPath: string,
    records: ConnectorRecord[],
    tableSpec: BaseTableSpec<T>,
  ): Promise<{ path: string; content: string }[]> {
    const trx = await this.getKnex().transaction();
    const processedFiles: { path: string; content: string }[] = [];

    try {
      // Get prefix
      const prefix = parentPath === '/' ? '' : parentPath;

      /* 
         Legacy comments about folder name resolution...
         Folder name is now just the ID (UUID) or empty if root. 
         Client resolves display name via Folder entity.
      */

      for (const record of records) {
        // Convert to Front Matter markdown format
        const { content: frontMatterContent, metadata: frontMatterMetadata } = convertConnectorRecordToFrontMatter(
          record,
          { contentColumnId: tableSpec.mainContentColumnRemoteId, embedRemoteId: false },
        );

        // Generate a scratch ID for new records
        const fileId = createFileId();

        // Determine the file name - use title column if available, otherwise use the record ID
        let fileName = record.id;
        let fullPath = '';
        let attempts = 0;

        while (attempts < MAX_UNIQUE_FILE_NAME_ATTEMPTS) {
          if (tableSpec.titleColumnRemoteId) {
            const column = tableSpec.columns.find((c) => _.isEqual(c.id.remoteId, tableSpec.titleColumnRemoteId));
            const titleValue = record.fields[column?.id.wsId ?? ''];
            if (titleValue && typeof titleValue === 'string') {
              fileName = titleValue;
            }
          }

          if (attempts > 0) {
            fileName = normalizeFileName(fileName) + '-' + attempts + '.md';
          }

          if (!fileName.endsWith('.md')) {
            fileName += '.md';
          }

          fullPath = `${prefix}/${fileName}`;

          // Check if another file (not this record) has the same filename
          const existingFileWithPath = await trx<FileDbRecord>(FILES_TABLE)
            .withSchema(workbookId)
            .where(FOLDER_ID_COLUMN, folderId)
            .where(FILE_NAME_COLUMN, fileName)
            .whereNot(REMOTE_ID_COLUMN, record.id) // Exclude the current record's file
            .first();

          if (!existingFileWithPath) {
            break;
          }
          attempts++;
        }

        if (attempts >= MAX_UNIQUE_FILE_NAME_ATTEMPTS) {
          throw new Error(
            `Failed to generate a unique file name for record ${record.id} after 20 attempts: ${fullPath}`,
          );
        }

        // Check if file with this remote_id already exists
        const existingFile = await trx<FileDbRecord>(FILES_TABLE)
          .withSchema(workbookId)
          .where(REMOTE_ID_COLUMN, record.id)
          .where(FOLDER_ID_COLUMN, folderId)
          .first();

        if (existingFile) {
          // Update existing file - including name/path if title column changed
          await trx(FILES_TABLE)
            .withSchema(workbookId)
            .where(FILE_ID_COLUMN, existingFile[FILE_ID_COLUMN])
            .update({
              [FILE_NAME_COLUMN]: fileName,
              [PATH_COLUMN]: fullPath,
              [ORIGINAL_COLUMN]: frontMatterContent, // this resets the original content new value from the connector
              [CONTENT_COLUMN]: frontMatterContent,
              [METADATA_COLUMN]: frontMatterMetadata,
              [DIRTY_COLUMN]: false, // Reset dirty flag since content matches remote
              [ERRORS_COLUMN]: record.errors || {},
              [UPDATED_AT_COLUMN]: trx.raw('CURRENT_TIMESTAMP'),
            });
        } else {
          // Insert new file
          await trx(FILES_TABLE)
            .withSchema(workbookId)
            .insert({
              [FILE_ID_COLUMN]: fileId,
              [REMOTE_ID_COLUMN]: record.id,
              [FOLDER_ID_COLUMN]: folderId,
              [PATH_COLUMN]: fullPath,
              [FILE_NAME_COLUMN]: fileName,
              [CONTENT_COLUMN]: frontMatterContent,
              [ORIGINAL_COLUMN]: frontMatterContent,
              [SUGGESTED_COLUMN]: null,
              [METADATA_COLUMN]: frontMatterMetadata,
              [CREATED_AT_COLUMN]: trx.raw('CURRENT_TIMESTAMP'),
              [UPDATED_AT_COLUMN]: trx.raw('CURRENT_TIMESTAMP'),
              [DELETED_COLUMN]: false,
              [DIRTY_COLUMN]: false, // New files from connector are clean
              [ERRORS_COLUMN]: record.errors || {},
            });
        }
        processedFiles.push({ path: fullPath, content: frontMatterContent });
      }

      await trx.commit();
      return processedFiles;
    } catch (error) {
      await trx.rollback();
      throw error;
    }
  }

  async resetSeenFlagForFolder(workbookId: WorkbookId, folderId: FolderId): Promise<void> {
    await this.getKnex()<FileDbRecord>(FILES_TABLE)
      .withSchema(workbookId)
      .where(FOLDER_ID_COLUMN, folderId)
      .update({ [SEEN_COLUMN]: false });
  }

  /**
   * Updates the remote ID, name, and path for a file after publishing.
   * Sets original to current content so future edits are recognized as updates, not creates.
   * Also marks the file as clean (not dirty).
   *
   * @param workbookId - The workbook ID
   * @param fileId - The file ID to update
   * @param remoteId - The remote ID from the connector
   * @param fileName - The new file name
   * @param filePath - The new file path
   * @param trx - Optional Knex transaction. If not provided, uses knex directly
   */
  async updateFileAfterPublishing(
    workbookId: WorkbookId,
    fileId: FileId,
    remoteId: string,
    fileName: string,
    filePath: string,
    trx?: Knex.Transaction,
  ): Promise<void> {
    const db = trx || this.getKnex();
    await db(FILES_TABLE)
      .withSchema(workbookId)
      .where(FILE_ID_COLUMN, fileId)
      .update({
        [REMOTE_ID_COLUMN]: remoteId,
        [FILE_NAME_COLUMN]: fileName,
        [PATH_COLUMN]: filePath,
        [ORIGINAL_COLUMN]: db.raw('??', [CONTENT_COLUMN]),
        [DIRTY_COLUMN]: false,
      });
  }

  /**
   * Hard deletes files from the database.
   *
   * @param workbookId - The workbook ID
   * @param fileIds - Array of file IDs to delete
   * @param trx - Optional Knex transaction. If not provided, uses knex directly
   */
  async hardDeleteFiles(workbookId: WorkbookId, fileIds: FileId[], trx?: Knex.Transaction): Promise<void> {
    const db = trx || this.getKnex();
    await db(FILES_TABLE).withSchema(workbookId).whereIn(FILE_ID_COLUMN, fileIds).delete();
  }

  /**
   * Marks files as clean (not dirty).
   *
   * @param workbookId - The workbook ID
   * @param fileIds - Array of file IDs to mark as clean
   * @param trx - Optional Knex transaction. If not provided, uses knex directly
   */
  async markFilesAsClean(workbookId: WorkbookId, fileIds: FileId[], trx?: Knex.Transaction): Promise<void> {
    const db = trx || this.getKnex();
    await db(FILES_TABLE)
      .withSchema(workbookId)
      .whereIn(FILE_ID_COLUMN, fileIds)
      .update({
        [DIRTY_COLUMN]: false,
      });
  }

  /**
   * Iterates over all dirty files matching a specific operation type.
   * Processes files in batches and executes a callback for each batch.
   *
   * @param workbookId - The workbook ID
   * @param operation - The type of operation: 'create', 'update', or 'delete'
   * @param batchSize - Number of files to process per batch
   * @param callback - Function to execute for each batch of files
   * @param markAsClean - Whether to mark processed files as clean (not dirty)
   * @returns Total number of files processed
   */
  async forAllDirtyFiles(
    workbookId: WorkbookId,
    operation: 'create' | 'update' | 'delete',
    batchSize: number,
    callback: (files: FileDbRecord[], trx: Knex.Transaction) => Promise<void>,
    markAsClean: boolean,
  ): Promise<number> {
    let processedCount = 0;
    const knex = this.getKnex();

    await knex.transaction(async (trx) => {
      const query = trx<FileDbRecord>(FILES_TABLE)
        .withSchema(workbookId)
        .select('*')
        .where(DIRTY_COLUMN, true)
        .orderBy('id')
        .forUpdate()
        .skipLocked();

      // Filter by operation type
      switch (operation) {
        case 'create':
          // New files: no original content
          query.whereNull(ORIGINAL_COLUMN);
          break;
        case 'update':
          // Modified files: has original, not deleted
          query.whereNotNull(ORIGINAL_COLUMN).where(DELETED_COLUMN, false);
          break;
        case 'delete':
          // Deleted files
          query.where(DELETED_COLUMN, true);
          break;
      }

      const allFiles = await query;
      processedCount = allFiles.length;

      if (allFiles.length > 0) {
        // Process files in batches
        for (let i = 0; i < allFiles.length; i += batchSize) {
          const batch = allFiles.slice(i, i + batchSize);
          await callback(batch, trx);

          // Mark files as clean if requested
          if (markAsClean) {
            const fileIds = batch.map((f) => f.id as FileId);
            await this.markFilesAsClean(workbookId, fileIds, trx);
          }
        }
      }
    });

    return processedCount;
  }

  /**
   * Counts the expected number of create, update, and delete operations for files in a folder.
   *
   * @param workbookId - The workbook ID
   * @param folderId - The folder ID to count operations for
   * @returns Object with counts for creates, updates, and deletes
   */
  async countExpectedOperations(
    workbookId: WorkbookId,
    folderId: FolderId,
  ): Promise<{ creates: number; updates: number; deletes: number }> {
    const knex = this.getKnex();

    const result = await knex.transaction(async (trx) => {
      // Query files in this folder that are dirty
      const query = trx<FileDbRecord>(FILES_TABLE)
        .withSchema(workbookId)
        .where(FOLDER_ID_COLUMN, folderId)
        .where(DIRTY_COLUMN, true);

      // Use a single query with conditional sums similar to snapshot-db
      const counts = await query
        .sum({
          creates: trx.raw(`CASE WHEN ?? IS NULL THEN 1 ELSE 0 END`, [ORIGINAL_COLUMN]),
          deletes: trx.raw(`CASE WHEN ?? = true THEN 1 ELSE 0 END`, [DELETED_COLUMN]),
          updates: trx.raw(`CASE WHEN ?? IS NOT NULL AND ?? = false AND ?? != ?? THEN 1 ELSE 0 END`, [
            ORIGINAL_COLUMN,
            DELETED_COLUMN,
            ORIGINAL_COLUMN,
            CONTENT_COLUMN,
          ]),
        })
        .first();

      return {
        creates: parseInt((counts?.creates as string) || '0', 10),
        updates: parseInt((counts?.updates as string) || '0', 10),
        deletes: parseInt((counts?.deletes as string) || '0', 10),
      };
    });

    return result;
  }

  async upsertFilesFromConnectorFiles(
    workbookId: WorkbookId,
    folderId: string,
    parentPath: string,
    records: ConnectorFile[],

    tableSpec: BaseJsonTableSpec,
  ): Promise<{ path: string; content: string }[]> {
    const trx = await this.getKnex().transaction();
    // Get prefix
    const prefix = parentPath === '/' ? '' : parentPath;
    const idColumnRemoteId = tableSpec.idColumnRemoteId;
    const processedFiles: { path: string; content: string }[] = [];

    try {
      // Query existing filenames in this folder for dedup (single query, not per-record)
      const existingFiles = await trx<FileDbRecord>(FILES_TABLE)
        .withSchema(workbookId)
        .where(FOLDER_ID_COLUMN, folderId)
        .select(FILE_NAME_COLUMN, REMOTE_ID_COLUMN);

      const usedFileNames = new Set<string>();
      const existingNameByRemoteId = new Map<string, string>();
      for (const f of existingFiles) {
        usedFileNames.add(f[FILE_NAME_COLUMN]);
        if (f[REMOTE_ID_COLUMN]) {
          existingNameByRemoteId.set(f[REMOTE_ID_COLUMN], f[FILE_NAME_COLUMN]);
        }
      }

      for (const record of records) {
        const content = JSON.stringify(record, null, 2);
        const metadata = {};

        // Generate a scratch ID for new records
        const fileId = createFileId();

        const recordId = String(record[idColumnRemoteId]);

        // Remove existing name from used set so this record can reclaim it
        const existingName = existingNameByRemoteId.get(recordId);
        if (existingName) {
          usedFileNames.delete(existingName);
        }

        // Resolve filename: slug > title > id
        const slugValue = tableSpec.slugColumnRemoteId
          ? (_.get(record, tableSpec.slugColumnRemoteId) as string | undefined)
          : undefined;
        const titleValue = tableSpec.titleColumnRemoteId
          ? (_.get(record, tableSpec.titleColumnRemoteId[0]) as string | undefined)
          : undefined;

        const baseName = resolveBaseFileName({ slugValue, titleValue, idValue: recordId });
        const fileName = deduplicateFileName(baseName, '.json', usedFileNames, recordId);
        const fullPath = `${prefix}/${fileName}`;

        // Check if file with this remote_id already exists
        const existingFile = await trx<FileDbRecord>(FILES_TABLE)
          .withSchema(workbookId)
          .where(REMOTE_ID_COLUMN, recordId)
          .where(FOLDER_ID_COLUMN, folderId)
          .first();

        if (existingFile) {
          // Update existing file - including name/path if title column changed
          await trx(FILES_TABLE)
            .withSchema(workbookId)
            .where(FILE_ID_COLUMN, existingFile[FILE_ID_COLUMN])
            .update({
              [FILE_NAME_COLUMN]: fileName,
              [PATH_COLUMN]: fullPath,
              [ORIGINAL_COLUMN]: content, // this resets the original content new value from the connector
              [CONTENT_COLUMN]: content,
              [METADATA_COLUMN]: metadata,
              [DIRTY_COLUMN]: false, // Reset dirty flag since content matches remote
              [ERRORS_COLUMN]: {},
              [UPDATED_AT_COLUMN]: trx.raw('CURRENT_TIMESTAMP'),
            });
        } else {
          // Insert new file
          await trx(FILES_TABLE)
            .withSchema(workbookId)
            .insert({
              [FILE_ID_COLUMN]: fileId,
              [REMOTE_ID_COLUMN]: recordId,
              [FOLDER_ID_COLUMN]: folderId,
              [PATH_COLUMN]: fullPath,
              [FILE_NAME_COLUMN]: fileName,
              [CONTENT_COLUMN]: content,
              [ORIGINAL_COLUMN]: content,
              [SUGGESTED_COLUMN]: null,
              [METADATA_COLUMN]: {},
              [CREATED_AT_COLUMN]: trx.raw('CURRENT_TIMESTAMP'),
              [UPDATED_AT_COLUMN]: trx.raw('CURRENT_TIMESTAMP'),
              [DELETED_COLUMN]: false,
              [DIRTY_COLUMN]: false, // New files from connector are clean
              [ERRORS_COLUMN]: {},
            });
        }
        processedFiles.push({ path: fullPath, content });
      }

      await trx.commit();
      return processedFiles;
    } catch (error) {
      await trx.rollback();
      throw error;
    }
  }

  public getKnex(): Knex {
    if (!this.knex) {
      throw new Error('Expected knex to not be undefined');
    }
    return this.knex;
  }
}

/* * * * * * * * * * * * * * * * * * * * * * * *
 *
 * Utility functions
 *
 * * * * * * * * * * * * * * * * * * * * * * * */

/**
 * Converts a ConnectorRecord to Front Matter markdown format.
 * The main content body is extracted from the field specified by mainContentColumnRemoteId in the TableSpec.
 * All other fields are stored as metadata in the YAML front matter.
 *
 * @param record - The ConnectorRecord to convert
 * @param tableSpec - TableSpec containing column definitions and mainContentColumnRemoteId
 * @returns Front Matter markdown string
 */
export function convertConnectorRecordToFrontMatter(
  record: ConnectorRecord,
  options: {
    contentColumnId?: string[];
    embedRemoteId?: boolean;
  },
): { content: string; metadata: Record<string, unknown> } {
  const { contentColumnId, embedRemoteId } = options;
  // Determine the main content column key
  let contentKey: string | undefined;
  if (contentColumnId && contentColumnId.length > 0) {
    // this is likely incorrect - need to handle the string array case
    contentKey = contentColumnId[0];
  }

  // Extract main content and metadata from record fields
  let bodyContent = '';
  const metadata: Record<string, unknown> = {};

  if (embedRemoteId) {
    metadata['remoteId'] = record.id;
  }

  for (const [key, value] of Object.entries(record.fields)) {
    if (contentKey && key === contentKey) {
      // This is the main content field
      bodyContent =
        typeof value === 'string' ? value : value === null || value === undefined ? '' : JSON.stringify(value, null, 2);
    } else {
      // All other fields go to metadata
      metadata[key] = value === null || value === undefined ? '' : value;
    }
  }
  const contentYaml = matter.stringify(bodyContent, metadata);

  // Convert to Front Matter markdown format
  return { content: contentYaml, metadata };
}

/**
 * Converts a file database record to a connector record format.
 * Parses the file content as markdown with front matter and extracts fields.
 *
 * @param file - The file database record
 * @param tableSpec - Table specification for field mapping
 * @returns ConnectorRecord ready for publishing
 */
export function convertFileToConnectorRecord<T extends BaseColumnSpec>(
  workbookId: WorkbookId,
  file: FileDbRecord,
  tableSpec: BaseTableSpec<T>,
): ConnectorRecord {
  const fields: Record<string, unknown> = {};

  // Parse the file content to extract front matter metadata
  if (file.content) {
    try {
      const parsed = matter(file.content);

      // Add metadata fields
      Object.assign(fields, parsed.data);

      // Add the main content to the main content field if specified
      if (tableSpec.mainContentColumnRemoteId && tableSpec.mainContentColumnRemoteId[0]) {
        fields[tableSpec.mainContentColumnRemoteId[0]] = parsed.content;
      }
    } catch (error) {
      WSLogger.error({
        source: 'WorkbookDb',
        message: `Failed to parse file content as frontmatter`,
        stack: error instanceof Error ? error.stack : undefined,
        fileId: file.id,
        workbookId,
      });
      // If parsing fails, use content as-is for main content field
      if (tableSpec.mainContentColumnRemoteId && tableSpec.mainContentColumnRemoteId[0]) {
        fields[tableSpec.mainContentColumnRemoteId[0]] = file.content;
      }
    }
  }

  // Include metadata from the metadata column
  if (file.metadata && typeof file.metadata === 'object') {
    Object.assign(fields, file.metadata);
  }

  return {
    id: file.id as FileId,
    fields,
    errors: file.errors || {},
  };
}

export class FileNotFoundError extends Error {
  public readonly filePath: string;
  public readonly workbookId: WorkbookId;

  constructor(filePath: string, workbookId: WorkbookId, cause?: Error) {
    super(`File not found: ${filePath} in workbook ${workbookId}`, { cause });
    this.name = 'FileNotFoundError';
    this.filePath = filePath;
    this.workbookId = workbookId;
  }
}
